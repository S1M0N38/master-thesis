\chapter{Model Evaluation}
\label{ch:model-evaluation}

In this chapter, we will discuss all the components involved in evaluating a model's performance, i.e.\ how to derive the predicted class from the model's output (\Cref{sec:decoding}), various metrics (\Cref{sec:metrics}), projections (\Cref{sec:projections}), and adversarial attacks (\Cref{sec:adversarial-attacks-model-evaluation}).

\section{Decoding}
\label{sec:decoding}

As stated in \Cref{subsec:one-hot-encoding}, when using one-hot encoding and optimizing with cross-entropy loss, we compel the model's output $\hat{y}$ to amplify the probability associated with the correct class while disregarding the others. Thus, the focus is solely on a single component, and if the model is well-trained, its index corresponds to the ground truth class. In this case, it is sufficient to take the $\argmax$ over the model's output to obtain the predicted class.
Due to the trivial nature of this operation, it is often overlooked, but the process differs slightly when using alternative encodings (\Cref{subsec:hierarchical-encodings,subsec:description-encodings}).\medskip

Formally, obtaining the class from the output can be considered as the inverse of the encoding function $\phi$, that is
\begin{equation}
  \gls{decoder} : \mathcal{Y} \to \mathcal{C}
  : \hat{y} \mapsto \gls{predicted_class} := \gls{decoder}(\hat{y})
  \label{eq:decoding}
\end{equation}
hence the term \emph{decoding}.
For one-hot encoding, $\phi^{-1} := \argmax$, i.e.\ a function that returns the index of the maximum value of the vector given as input. In contrast, others encodings -- hierarchical and description encodings -- utilize multiple components in the model's output during training, so taking the $\argmax$ indiscriminately discards potentially useful information. Nevertheless, both loss functions employed -- cross-entropy loss and cosine distance -- aim to make the model's output resemble the ground truth encoding, so it is reasonable to consider the predicted class to be the one corresponding to the encoding most similar to the model's output.
To this end, we choose cosine similarity as the measure for such a quantity, i.e.\
\begin{equation}
  \phi^{-1}(\hat{y}) := \argmax_{c \in \mathcal{C}}
  \left( \gls{cosine_similarity} \left(\hat{y}, \phi(c) \right) \right)
  \label{eq:decoding-cos-sim}
\end{equation}
If $\phi$ is one-hot encoding, \Cref{eq:decoding-cos-sim} is equivalent to simply taking the $\argmax$ over the output vector.

An advantage of defining a decoding function based on encoding similarity is that it is compatible with different encoding schemes. For instance, selecting the highest component in a model's output trained using description encodings is nonsensical: the vector dimensions do not represent classes but are coordinates of a point in a high-dimensional space. What is significant is the relative distance of that point (class encoding) to other points (other class encodings).
Conversely, if components directly represent a class (e.g. hierarchical encodings), the provided decoding function operates as expected.
Another benefit is the ability to leverage information from all the output's components: we can not only attempt to identify the class present in the provided image but also discern what the model is confident the image is not (e.g. the class with the encoding that differs the most from $\hat{y}$).\medskip

The concept of decoding could be straightforwardly extended to the top-\gls{number_predicted_classes} predicted classes. Instead of returning the class associated with the most similar encoding, we simply return the top-\gls{number_predicted_classes} most similar classes.

\section{Metrics}
\label{sec:metrics}
Russakovsky et al.~\cite{ImagenetLargeRussak2014} introduced the \acrfull{ilsvrc}, which became the de facto benchmark to evaluate image classification models.
Even though they propose the use of top-\gls{number_predicted_classes} and hierarchical measures to assess a model's performance, they conclude ``[...] all three measures of error (top-5, top-1, and hierarchical) produced the same ordering of results. Thus, since \acrshort{ilsvrc} 2012 we have been exclusively using the top-5 metric, which is the simplest and most suitable to the dataset.''
The deep learning community prioritizes achieving high top-\gls{number_predicted_classes} accuracies as these are easier to compute for every dataset.

\paragraph{Quantity \& Quality}
\label{par:metrics-quantity-quality}
However, this work focuses on developing models that not only produce fewer errors but also less severe ones. While top-\gls{number_predicted_classes} accuracies are useful to capture the \emph{quantity} aspect, they do not provide any information about their \emph{quality}.
For example, confusing a \texttt{dog} for a \texttt{cat} can be considered a milder error compared to a \texttt{dog} - \texttt{car} misclassification; both are mammals and, as such, share some distinguishing features like fur, a head, a pair of eyes, four paws, etc. Cars present straight lines, a uniform coated surface, and an absence of typical traits of living things, etc.
This notion of visual similarity is somewhat encoded in the classes' hierarchy, so it makes sense to use distances on a hierarchical tree to quantify the severity of mistakes.\footnote{The assumption that a hierarchy carries information about visual characteristics is indeed strong and must be empirically checked for dataset-hierarchy pairs considered.
Datasets used in this work satisfy the ansatz, so hierarchical similarity is a good proxy for visual similarity.} In the following sections, we introduce some performance metrics that enable this quantitative/qualitative error assessment.

\paragraph{Levels}
\label{par:metrics-levels}
Having access to datasets equipped with a hierarchy introduces a new dimension to evaluate models across: their performance at different levels of the hierarchy.
With reference to the toy dataset in~\Cref{fig:03/toy-dataset}, suppose we are interested in a coarser-grained classification that distinguishes between Fruits, Animals, and Vehicles (level 1). In this case, after applying the decoding to \gls{output} to get \gls{predicted_class}, we need to map the predicted class to its ancestor in the hierarchy, obtaining the \emph{level-1 predicted class}. We can produce an even coarser classification discriminating between Natural vs.\ Artificial instances by mapping the level-1 predicted class to its ancestor, obtaining the \emph{level-2 predicted class}, and so on.
We denote the predicted class at the l-th level as $\hat{c}^l$ and $c^l$ as its corresponding ground truth; the index $l$ is omitted at level zero.

\subsection{Error Rate}
\label{subsec:error-rate}
There is no need to reinvent the wheel to give an estimate of the amount of error: top-1 accuracy (or simply accuracy) provides such an estimation.
However, for easier comparison with other metrics, we use the \emph{top-1 error rate} (or simply error rate), which is defined as $1 - \,$accuracy. The usage of a \emph{confusion matrix} makes the definition of the error rate, and the subsequent metrics, straightforward at the cost of extensibility to top-\gls{number_predicted_classes} versions.

\paragraph{Confusion Matrix}
\label{par:confusion-matrix}
It is a square matrix $|\mathcal{C}| \times |\mathcal{C}|$ whose rows are ground-truth classes \gls{class} and columns are predicted classes \gls{predicted_class}. Its entries $m_{ij}$ count the number of times a model produces the pair $(c_i, \hat{c}_j)$ when evaluated on a dataset.
For example, a model applied to the example dataset can produce confusion matrices at
different hierarchical levels as in~\Cref{fig:04/confusion-matrices}.
\begin{figure}[htbp]
  \centering
  \begin{subfigure}{0.35\textwidth}
    \ctikzfig{04/confusion-matrix-level-0}
  \end{subfigure}
  \begin{subfigure}{0.30\textwidth}
    \ctikzfig{04/confusion-matrix-level-1}
  \end{subfigure}
  \begin{subfigure}{0.25\textwidth}
    \ctikzfig{04/confusion-matrix-level-2}
  \end{subfigure}
  \caption{Example of confusion matrices: $m_{ij}^l$}
  \label{fig:04/confusion-matrices}
\end{figure}
\medskip

Using the confusion matrix, the error rate at the l-th level is the sum of the off-diagonal elements divided by the sum of all elements, i.e.\
\begin{equation}
  \textrm{error rate} :=
  \sum_{i \ne j} m_{ij}^l \bigg/ \sum_{i, \,j} m_{ij}^l.
  \label{eq:error-rate}
\end{equation}


\subsection{Hierarchical Distance Mistake}
\label{subsec:hierarchical-distance-mistake}
\emph{Hierarchical distance mistake} is a metric that takes into account the hierarchy to quantify the severity of a mistake, i.e.\ it makes use of the \acrshort{lca} height $h_{ij}$ as a weighting factor (see example in \Cref{fig:03/lca-height-matrix}).
The Hierarchical distance mistake is defined to be
\begin{equation}
  \textrm{hier.\ dist.\ mistake} :=
  \sum_{i, \, j} m_{ij}^l \, h_{ij}^l \bigg/ \sum_{i \ne j} m_{ij}^l.
  \label{eq:hierarchical-distance-mistake}
\end{equation}
Thus, it is the average \acrshort{lca} height between predicted and ground-truth classes.
Note that $h_{ii}$ are all zeros, so we are effectively summing only the weighted errors in the numerator, while the denominator is the total number of errors. Due to its definition, it is not related to the error rate; i.e.\ it is possible to have a low error rate (few errors) but a high hierarchical distance mistake (those errors are severe).

\paragraph{Error rate -- Hier.\ dist.\ mistake}
\label{par:error-rate-hier-dist-mistake}
In order to compare models at a glance, we can plot the error rate versus hierarchical distance mistake on a two-dimensional scatter plot.
The x-axis represents the amount of error (error rate), while the y-axis represents the severity of errors. Each point on the scatter plot corresponds to a trained model, and the overall best model is the one in the bottom-left corner.
Moreover, we can draw this plot for different levels in the hierarchy, highlighting the fact that milder errors at lower levels usually result in fewer errors at higher ones.
\begin{figure}[htbp]
  \ctikzfig{04/error-rate-hier-dist-mistake}
  \caption{Quadrants in error rate vs hier.\ dist.\ mistake plot}
  \label{fig:04/error-rate-hier-dist-mistake}
\end{figure}

\subsection{Hierarchical Distance}
\label{subsec:hierarchical-distance}
\emph{Hierarchical distance} is somewhat hybrid: it accounts for both the quality and quantity of errors. Its definition is almost identical to that of hierarchical distance mistake but instead of dividing by the number of errors, we divide by the total number of samples in the dataset, i.e.\
\begin{equation}
  \textrm{hier.\ dist.\ } :=
  \sum_{i, \, j} m_{ij}^l \, h_{ij}^l \bigg/ \sum_{i, \, j} m_{ij}^l.
  \label{eq:hierarchical-distance}
\end{equation}
If the model produces few errors, the off-diagonal values in the confusion matrix will be smaller, which are the only ones multiplied by non-zero values, hence the numerator is smaller. The denominator always stays the same, resulting in a lower value for hierarchical distance.

\section{Projections}
\label{sec:projections}
% TODO: Features vector, clustering, plots ...

\subsection{Encodings projections}
\label{subsec:encodings-projections}
\begin{itemize}
  \item introduce encodings projections
  \item are important for description encodings
  \item briefly explain UMAP
  \item  We use UMAP because it scale better for large number of points so we
    can reuse it in the next subsection
\end{itemize}

\subsection{Features projections}
\label{subsec:features-projections}
\begin{itemize}
  \item Visual inspections of model's features vectors (the last layer before
    output)
  \item Clustering metrics as measure for internal structured representation
\end{itemize}


\section{Adversarial attacks}
\label{sec:adversarial-attacks}
\begin{itemize}
  \item What are adversarial attacks
  \item Somewhat detailed descriptions of 3 attacks
\end{itemize}


% TODO: How to get predicted class from model's output. Explain the difference
% between argmax and align+argmax For one-hot encoding the two approaches are
% equivalent. For others encodings there is some difference. Explore and Explain
% it This is a clever way to fully use information about what models predict,
% not only this take into account the fact that the highest probability is the
% correct class, but also what the model thinks the image is not. Effectively
% denoising the prediction, a sort of top-\gls{number_predicted_classes}
% approach with a single class as output.
%
% TODO: Motivate why we are evaluating all these different aspect
% TODO: Metric definitions.
% TODO: Features vector, clustering, plots ...
% TODO: Adversarial attack: def, how they works, strength weakness
