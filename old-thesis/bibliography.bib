@article{1903.01182v2,
  abstract = {Learning with a primary objective, such as softmax cross entropy for classification and sequence generation, has been the norm for training deep neural networks for years. Although being a widely-adopted approach, using cross entropy as the primary objective exploits mostly the information from the ground-truth class for maximizing data likelihood, and largely ignores information from the complement (incorrect) classes. We argue that, in addition to the primary objective, training also using a complement objective that leverages information from the complement classes can be effective in improving model performance. This motivates us to study a new training paradigm that maximizes the likelihood of the groundtruth class while neutralizing the probabilities of the complement classes. We conduct extensive experiments on multiple tasks ranging from computer vision to natural language understanding. The experimental results confirm that, compared to the conventional training with just one primary objective, training also with the complement objective further improves the performance of the state-of-the-art models across all tasks. In addition to the accuracy improvement, we also show that models trained with both primary and complement objectives are more robust to single-step adversarial attacks.},
  archiveprefix = {arXiv},
  author = {Chen, Hao-Yun and Wang, Pei-Hsin and Liu, Chun-Hao and Chang, Shih-Chieh and Pan, Jia-Yu and Chen, Yu-Ting and Wei, Wei and Juan, Da-Cheng},
  eprint = {1903.01182v2},
  file = {1903.01182v2.pdf},
  month = {Mar},
  primaryclass = {cs.LG},
  title = {Complement Objective Training},
  url = {http://arxiv.org/abs/1903.01182v2},
  year = {2019},
}

@article{TheShapeOfLeVierin2021,
  abstract = {Learning curves provide insight into the dependence of a learner's generalization performance on the training set size. This important tool can be used for model selection, to predict the effect of more training data, and to reduce the computational complexity of model training and hyperparameter tuning. This review recounts the origins of the term, provides a formal definition of the learning curve, and briefly covers basics such as its estimation. Our main contribution is a comprehensive overview of the literature regarding the shape of learning curves. We discuss empirical and theoretical evidence that supports well-behaved curves that often have the shape of a power law or an exponential. We consider the learning curves of Gaussian processes, the complex shapes they can display, and the factors influencing them. We draw specific attention to examples of learning curves that are ill-behaved, showing worse learning performance with more training data. To wrap up, we point out various open problems that warrant deeper empirical and theoretical investigation. All in all, our review underscores that learning curves are surprisingly diverse and no universal model can be identified.},
  archiveprefix = {arXiv},
  author = {Viering, Tom and Loog, Marco},
  eprint = {2103.10948v2},
  file = {2103.10948v2.pdf},
  month = {Mar},
  primaryclass = {cs.LG},
  title = {The Shape of Learning Curves: a Review},
  url = {http://arxiv.org/abs/2103.10948v2},
  year = {2021},
}

@article{1412.6572v3,
  abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
  archiveprefix = {arXiv},
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  eprint = {1412.6572v3},
  file = {1412.6572v3.pdf},
  month = {Dec},
  primaryclass = {stat.ML},
  title = {Explaining and Harnessing Adversarial Examples},
  url = {http://arxiv.org/abs/1412.6572v3},
  year = {2014},
}

@article{DeepLearningOBarz2019,
  abstract = {Two things seem to be indisputable in the contemporary deep learning discourse: 1. The categorical cross-entropy loss after softmax activation is the method of choice for classification. 2. Training a CNN classifier from scratch on small datasets does not work well. In contrast to this, we show that the cosine loss function provides significantly better performance than cross-entropy on datasets with only a handful of samples per class. For example, the accuracy achieved on the CUB-200-2011 dataset without pre-training is by 30\% higher than with the cross-entropy loss. Further experiments on other popular datasets confirm our findings. Moreover, we demonstrate that integrating prior knowledge in the form of class hierarchies is straightforward with the cosine loss and improves classification performance further.},
  archiveprefix = {arXiv},
  author = {Barz, Bj\"{o}rn and Denzler, Joachim},
  eprint = {1901.09054v2},
  file = {1901.09054v2.pdf},
  month = {Jan},
  note = {2020 IEEE Winter Conference on Applications of Computer Vision   (WACV), Snowmass Village, CO, USA, 2020},
  primaryclass = {cs.LG},
  title = {Deep Learning on Small Datasets without Pre-Training using Cosine Loss},
  url = {http://arxiv.org/abs/1901.09054v2},
  year = {2019},
}

@inproceedings{DeviseADeepFrome2013,
  abstract = {Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources - such as text data - both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18\% across thousands of novel labels never seen by the visual model.},
  address = {Red Hook, NY, USA},
  author = {Frome, Andrea and Corrado, Greg S. and Shlens, Jonathon and Bengio, Samy and Dean, Jeffrey and Ranzato, Marc'Aurelio and Mikolov, Tomas},
  booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
  location = {Lake Tahoe, Nevada},
  pages = {2121\textendash{}2129},
  publisher = {Curran Associates Inc.},
  series = {NIPS'13},
  title = {DeViSE: A Deep Visual-Semantic Embedding Model},
  year = {2013},
}

@article{1911.07257v1,
  abstract = {Label hierarchies widely exist in many vision-related problems, ranging from explicit label hierarchies existed in image classification to latent label hierarchies existed in semantic segmentation. Nevertheless, state-of-the-art methods often deploy cross-entropy loss that implicitly assumes class labels to be exclusive and thus independence from each other. Motivated by the fact that classes from the same parental category usually share certain similarity, we design a new training diagram called Hierarchical Complement Objective Training (HCOT) that leverages the information from label hierarchy. HCOT maximizes the probability of the ground truth class, and at the same time, neutralizes the probabilities of rest of the classes in a hierarchical fashion, making the model take advantage of the label hierarchy explicitly. The proposed HCOT is evaluated on both image classification and semantic segmentation tasks. Experimental results confirm that HCOT outperforms state-of-the-art models in CIFAR-100, ImageNet-2012, and PASCAL-Context. The study further demonstrates that HCOT can be applied on tasks with latent label hierarchies, which is a common characteristic in many machine learning tasks.},
  archiveprefix = {arXiv},
  author = {Chen, Hao-Yun and Tsai, Li-Huang and Chang, Shih-Chieh and Pan, Jia-Yu and Chen, Yu-Ting and Wei, Wei and Juan, Da-Cheng},
  eprint = {1911.07257v1},
  file = {1911.07257v1.pdf},
  month = {Nov},
  primaryclass = {cs.CV},
  title = {Learning with Hierarchical Complement Objective},
  url = {http://arxiv.org/abs/1911.07257v1},
  year = {2019},
}

@article{HierarchyBasedBarz2018,
  abstract = {Deep neural networks trained for classification have been found to learn powerful image representations, which are also often used for other tasks such as comparing images w.r.t. their visual similarity. However, visual similarity does not imply semantic similarity. In order to learn semantically discriminative features, we propose to map images onto class embeddings whose pair-wise dot products correspond to a measure of semantic similarity between classes. Such an embedding does not only improve image retrieval results, but could also facilitate integrating semantics for other tasks, e.g., novelty detection or few-shot learning. We introduce a deterministic algorithm for computing the class centroids directly based on prior world-knowledge encoded in a hierarchy of classes such as WordNet. Experiments on CIFAR-100, NABirds, and ImageNet show that our learned semantic image embeddings improve the semantic consistency of image retrieval results by a large margin.},
  archiveprefix = {arXiv},
  author = {Barz, Bj\"{o}rn and Denzler, Joachim},
  doi = {10.1109/WACV.2019.00073},
  eprint = {1809.09924v4},
  file = {1809.09924v4.pdf},
  month = {Sep},
  note = {2019 IEEE Winter Conference on Applications of Computer Vision   (WACV), Waikoloa Village, HI, USA, 2019, pp. 638-647},
  primaryclass = {cs.CV},
  title = {Hierarchy-based Image Embeddings for Semantic Image Retrieval},
  url = {http://arxiv.org/abs/1809.09924v4},
  year = {2018},
}

@inproceedings{UnderstandingOLiuY2010,
  author = {Liu, Yanchi and Li, Zhongmou and Xiong, Hui and Gao, Xuedong and Wu, Junjie},
  booktitle = {2010 IEEE 10th International Conference on Data Mining (ICDM)},
  doi = {10.1109/icdm.2010.35},
  journal = {2010 IEEE International Conference on Data Mining},
  month = {12},
  publisher = {IEEE},
  title = {Understanding of Internal Clustering Validation Measures},
  url = {http://dx.doi.org/10.1109/icdm.2010.35},
  venue = {Sydney, Australia},
  year = {2010},
}

@article{LearningHierarGarg2022,
  abstract = {Label hierarchies are often available apriori as part of biological taxonomy or language datasets WordNet. Several works exploit these to learn hierarchy aware features in order to improve the classifier to make semantically meaningful mistakes while maintaining or reducing the overall error. In this paper, we propose a novel approach for learning Hierarchy Aware Features (HAF) that leverages classifiers at each level of the hierarchy that are constrained to generate predictions consistent with the label hierarchy. The classifiers are trained by minimizing a Jensen-Shannon Divergence with target soft labels obtained from the fine-grained classifiers. Additionally, we employ a simple geometric loss that constrains the feature space geometry to capture the semantic structure of the label space. HAF is a training time approach that improves the mistakes while maintaining top-1 error, thereby, addressing the problem of cross-entropy loss that treats all mistakes as equal. We evaluate HAF on three hierarchical datasets and achieve state-of-the-art results on the iNaturalist-19 and CIFAR-100 datasets. The source code is available at https://github.com/07Agarg/HAF},
  archiveprefix = {arXiv},
  author = {Garg, Ashima and Sani, Depanshu and Anand, Saket},
  eprint = {2207.12646v1},
  file = {2207.12646v1.pdf},
  month = {Jul},
  primaryclass = {cs.CV},
  title = {Learning Hierarchy Aware Features for Reducing Mistake Severity},
  url = {http://arxiv.org/abs/2207.12646v1},
  year = {2022},
}

@article{1912.09393v2,
  abstract = {Deep neural networks have improved image classification dramatically over the past decade, but have done so by focusing on performance measures that treat all classes other than the ground truth as equally wrong. This has led to a situation in which mistakes are less likely to be made than before, but are equally likely to be absurd or catastrophic when they do occur. Past works have recognised and tried to address this issue of mistake severity, often by using graph distances in class hierarchies, but this has largely been neglected since the advent of the current deep learning era in computer vision. In this paper, we aim to renew interest in this problem by reviewing past approaches and proposing two simple modifications of the cross-entropy loss which outperform the prior art under several metrics on two large datasets with complex class hierarchies: tieredImageNet and iNaturalist'19.},
  archiveprefix = {arXiv},
  author = {Bertinetto, Luca and Mueller, Romain and Tertikas, Konstantinos and Samangooei, Sina and Lord, Nicholas A.},
  eprint = {1912.09393v2},
  file = {1912.09393v2.pdf},
  month = {Dec},
  primaryclass = {cs.CV},
  title = {Making Better Mistakes: Leveraging Class Hierarchies with Deep Networks},
  url = {http://arxiv.org/abs/1912.09393v2},
  year = {2019},
}

@article{1904.00887v4,
  abstract = {Deep neural networks are vulnerable to adversarial attacks, which can fool them by adding minuscule perturbations to the input images. The robustness of existing defenses suffers greatly under white-box attack settings, where an adversary has full knowledge about the network and can iterate several times to find strong perturbations. We observe that the main reason for the existence of such perturbations is the close proximity of different class samples in the learned feature space. This allows model decisions to be totally changed by adding an imperceptible perturbation in the inputs. To counter this, we propose to class-wise disentangle the intermediate feature representations of deep networks. Specifically, we force the features for each class to lie inside a convex polytope that is maximally separated from the polytopes of other classes. In this manner, the network is forced to learn distinct and distant decision regions for each class. We observe that this simple constraint on the features greatly enhances the robustness of learned models, even against the strongest white-box attacks, without degrading the classification performance on clean images. We report extensive evaluations in both black-box and white-box attack scenarios and show significant gains in comparison to state-of-the art defenses.},
  archiveprefix = {arXiv},
  author = {Mustafa, Aamir and Khan, Salman and Hayat, Munawar and Goecke, Roland and Shen, Jianbing and Shao, Ling},
  eprint = {1904.00887v4},
  file = {1904.00887v4.pdf},
  month = {Apr},
  primaryclass = {cs.CV},
  title = {Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks},
  url = {http://arxiv.org/abs/1904.00887v4},
  year = {2019},
}

@article{1903.09799v3,
  abstract = {Adversarial robustness has emerged as an important topic in deep learning as carefully crafted attack samples can significantly disturb the performance of a model. Many recent methods have proposed to improve adversarial robustness by utilizing adversarial training or model distillation, which adds additional procedures to model training. In this paper, we propose a new training paradigm called Guided Complement Entropy (GCE) that is capable of achieving "adversarial defense for free," which involves no additional procedures in the process of improving adversarial robustness. In addition to maximizing model probabilities on the ground-truth class like cross-entropy, we neutralize its probabilities on the incorrect classes along with a "guided" term to balance between these two terms. We show in the experiments that our method achieves better model robustness with even better performance compared to the commonly used cross-entropy training objective. We also show that our method can be used orthogonal to adversarial training across well-known methods with noticeable robustness gain. To the best of our knowledge, our approach is the first one that improves model robustness without compromising performance.},
  archiveprefix = {arXiv},
  author = {Chen, Hao-Yun and Liang, Jhao-Hong and Chang, Shih-Chieh and Pan, Jia-Yu and Chen, Yu-Ting and Wei, Wei and Juan, Da-Cheng},
  eprint = {1903.09799v3},
  file = {1903.09799v3.pdf},
  month = {Mar},
  primaryclass = {cs.LG},
  title = {Improving Adversarial Robustness via Guided Complement Entropy},
  url = {http://arxiv.org/abs/1903.09799v3},
  year = {2019},
}