abstract: While deep neural networks have been achieving state-of-the-art performance
  across a wide variety of applications, their vulnerability to adversarial attacks
  limits their widespread deployment for safety-critical applications. Alongside other
  adversarial defense approaches being investigated, there has been a very recent
  interest in improving adversarial robustness in deep neural networks through the
  introduction of perturbations during the training process. However, such methods
  leverage fixed, pre-defined perturbations and require significant hyper-parameter
  tuning that makes them very difficult to leverage in a general fashion. In this
  study, we introduce Learn2Perturb, an end-to-end feature perturbation learning approach
  for improving the adversarial robustness of deep neural networks. More specifically,
  we introduce novel perturbation-injection modules that are incorporated at each
  layer to perturb the feature space and increase uncertainty in the network. This
  feature perturbation is performed at both the training and the inference stages.
  Furthermore, inspired by the Expectation-Maximization, an alternating back-propagation
  training algorithm is introduced to train the network and noise parameters consecutively.
  Experimental results on CIFAR-10 and CIFAR-100 datasets show that the proposed Learn2Perturb
  method can result in deep neural networks which are $4-7\%$ more robust on $l_{\infty}$
  FGSM and PDG adversarial attacks and significantly outperforms the state-of-the-art
  against $l_2$ $C\&W$ attack and a wide range of well-known black-box attacks.
archiveprefix: arXiv
author: Jeddi, Ahmadreza and Shafiee, Mohammad Javad and Karg, Michelle and Scharfenberger,
  Christian and Wong, Alexander
author_list:
- family: Jeddi
  given: Ahmadreza
- family: Shafiee
  given: Mohammad Javad
- family: Karg
  given: Michelle
- family: Scharfenberger
  given: Christian
- family: Wong
  given: Alexander
eprint: 2003.01090v2
file: 2003.01090v2.pdf
files:
- tmpv83ofl-m.pdf
month: Mar
primaryclass: cs.CV
ref: 2003.01090v2
tags: CVPR2020
time-added: 2023-03-07-17:09:32
title: 'Learn2Perturb: an End-to-end Feature Perturbation Learning to Improve Adversarial
  Robustness'
type: article
url: http://arxiv.org/abs/2003.01090v2
year: '2020'
notes: 'Framework for producing perturbation duning training and inference at
  feature level. Tested on CIFAR-10 and CIFAR-100.' 
code: 'https://github.com/Ahmadreza-Jeddi/Learn2Perturb'
