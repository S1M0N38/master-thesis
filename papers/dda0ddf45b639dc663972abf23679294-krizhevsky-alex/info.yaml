abstract: 'Groups at MIT and NYU have collected a dataset of millions of tiny
  colour images from the web. It is, in principle, an excellent dataset for
  unsupervised training of deep generative models, but previous researchers who
  have tried this have found it dicult to learn a good set of lters from the
  images. We show how to train a multi-layer generative model that learns to
  extract meaningful features which resemble those found in the human visual
  cortex. Using a novel parallelization algorithm to distribute the work among
  multiple machines connected on a network, we show how training such a model can
  be done in reasonable time. A second problematic aspect of the tiny images
  dataset is that there are no reliable class labels which makes it hard to use
  for object recognition experiments. We created two sets of reliable labels. The
  CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has
  600 examples of each of 100 non-overlapping classes. Using these labels, we
  show that object recognition is signicantly improved by pre-training a layer of
  features on a large set of unlabeled tiny images.'
author: Krizhevsky, Alex
author_list:
- family: Krizhevsky
  given: Alex
files: []
papis_id: b415e647d8927bf20653ec069101b7aa
ref: LearningMultipKrizhe2009
title: Learning Multiple Layers of Features from Tiny Images
type: inproceedings
url: https://api.semanticscholar.org/CorpusID:18268744
year: 2009
