abstract: Batch normalization (BN) has been widely used in modern deep neural networks
  (DNNs) due to improved convergence. BN is observed to increase the model accuracy
  while at the cost of adversarial robustness. There is an increasing interest in
  the ML community to understand the impact of BN on DNNs, especially related to the
  model robustness. This work attempts to understand the impact of BN on DNNs from
  a non-robust feature perspective. Straightforwardly, the improved accuracy can be
  attributed to the better utilization of useful features. It remains unclear whether
  BN mainly favors learning robust features (RFs) or non-robust features (NRFs). Our
  work presents empirical evidence that supports that BN shifts a model towards being
  more dependent on NRFs. To facilitate the analysis of such a feature robustness
  shift, we propose a framework for disentangling robust usefulness into robustness
  and usefulness. Extensive analysis under the proposed framework yields valuable
  insight on the DNN behavior regarding robustness, e.g. DNNs first mainly learn RFs
  and then NRFs. The insight that RFs transfer better than NRFs, further inspires
  simple techniques to strengthen transfer-based black-box attacks.
archiveprefix: arXiv
author: Benz, Philipp and Zhang, Chaoning and Kweon, In So
author_list:
- family: Benz
  given: Philipp
- family: Zhang
  given: Chaoning
- family: Kweon
  given: In So
eprint: 2010.03316v2
file: 2010.03316v2.pdf
files:
- tmp0k5bx1i.pdf
month: Oct
primaryclass: cs.LG
ref: 2010.03316v2
tags: ICCV2021 adversarial-transerability batch-normalization
time-added: 2023-03-06-19:27:28
title: 'Batch Normalization Increases Adversarial Vulnerability and Decreases Adversarial
  Transferability: A Non-Robust Feature Perspective'
type: article
url: http://arxiv.org/abs/2010.03316v2
year: '2020'
notes: 'Batch Normalization (BN) is observed to increase the model accuracy
  while at the cost of adversarial robustness. Empirical evidence that BN make
  model more dependent on non-robust features (NRFs). Propose a framework for
  disentangling robust usefulness into robustness and usefulness.'
code: 'https://github.com/phibenz/adversarial_ml.research'
