abstract: Adversarial examples cause neural networks to produce incorrect outputs
  with high confidence. Although adversarial training is one of the most effective
  forms of defense against adversarial examples, unfortunately, a large gap exists
  between test accuracy and training accuracy in adversarial training. In this paper,
  we identify Adversarial Feature Overfitting (AFO), which may cause poor adversarially
  robust generalization, and we show that adversarial training can overshoot the optimal
  point in terms of robust generalization, leading to AFO in our simple Gaussian model.
  Considering these theoretical results, we present soft labeling as a solution to
  the AFO problem. Furthermore, we propose Adversarial Vertex mixup (AVmixup), a soft-labeled
  data augmentation approach for improving adversarially robust generalization. We
  complement our theoretical analysis with experiments on CIFAR10, CIFAR100, SVHN,
  and Tiny ImageNet, and show that AVmixup significantly improves the robust generalization
  performance and that it reduces the trade-off between standard accuracy and adversarial
  robustness.
archiveprefix: arXiv
author: Lee, Saehyung and Lee, Hyungyu and Yoon, Sungroh
author_list:
- family: Lee
  given: Saehyung
- family: Lee
  given: Hyungyu
- family: Yoon
  given: Sungroh
eprint: 2003.02484v3
file: 2003.02484v3.pdf
files:
- tmp6ku3br60.pdf
month: Mar
primaryclass: cs.CV
ref: 2003.02484v3
tags: CVPR2020
time-added: 2023-03-07-16:52:52
title: 'Adversarial Vertex Mixup: Toward Better Adversarially Robust   Generalization'
type: article
url: http://arxiv.org/abs/2003.02484v3
year: '2020'
notes: 'Soft labeling as solution to Adversarial Feature Overtting (AFO, a
  large gap between training accuracy and test accuracy cause by adversial
  training). Propose Adversarial Vertex mixup (AVmixup), a soft-labeled data
  augmentation approach. Test on CIFAR-10, CIFAR-100 and others. AVmixup
  significantly reduce trade-off std accuracy and adv rebustness.'
