abstract: Neural networks are vulnerable to adversarial examples, malicious inputs
  crafted to fool trained models. Adversarial examples often exhibit black-box transfer,
  meaning that adversarial examples for one model can fool another model. However,
  adversarial examples are typically overfit to exploit the particular architecture
  and feature representation of a source model, resulting in sub-optimal black-box
  transfer attacks to other target models. We introduce the Intermediate Level Attack
  (ILA), which attempts to fine-tune an existing adversarial example for greater black-box
  transferability by increasing its perturbation on a pre-specified layer of the source
  model, improving upon state-of-the-art methods. We show that we can select a layer
  of the source model to perturb without any knowledge of the target models while
  achieving high transferability. Additionally, we provide some explanatory insights
  regarding our method and the effect of optimizing for adversarial examples using
  intermediate feature maps. Our code is available at https://github.com/CUVL/Intermediate-Level-Attack.
archiveprefix: arXiv
author: Huang, Qian and Katsman, Isay and He, Horace and Gu, Zeqi and Belongie, Serge
  and Lim, Ser-Nam
author_list:
- family: Huang
  given: Qian
- family: Katsman
  given: Isay
- family: He
  given: Horace
- family: Gu
  given: Zeqi
- family: Belongie
  given: Serge
- family: Lim
  given: Ser-Nam
eprint: 1907.10823v3
file: 1907.10823v3.pdf
files:
- tmp5f12d8w6.pdf
month: Jul
primaryclass: cs.LG
ref: 1907.10823v3
tags: ICCV2019 attack
time-added: 2023-03-07-11:45:54
title: Enhancing Adversarial Example Transferability with an Intermediate Level   Attack
type: article
url: http://arxiv.org/abs/1907.10823v3
year: '2019'
notes: 'introduce the Intermediate Level Attack (ILA), which attempts to
  fine-tune an existing adversarial example for greater black-box
  transferability by increasing its perturbation on a pre-specified layer of
  the source model. Provide some explanatory about the effect of optimizing for
  adversarial examples using intermediate feature maps.'
code: 'https://github.com/CUAI/Intermediate-Level-Attack'
