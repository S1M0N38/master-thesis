abstract: 'Two things seem to be indisputable in the contemporary deep learning discourse:
  1. The categorical cross-entropy loss after softmax activation is the method of
  choice for classification. 2. Training a CNN classifier from scratch on small datasets
  does not work well. In contrast to this, we show that the cosine loss function provides
  significantly better performance than cross-entropy on datasets with only a handful
  of samples per class. For example, the accuracy achieved on the CUB-200-2011 dataset
  without pre-training is by 30% higher than with the cross-entropy loss. Further
  experiments on other popular datasets confirm our findings. Moreover, we demonstrate
  that integrating prior knowledge in the form of class hierarchies is straightforward
  with the cosine loss and improves classification performance further.'
archiveprefix: arXiv
author: Barz, Björn and Denzler, Joachim
author_list:
- family: Barz
  given: Björn
- family: Denzler
  given: Joachim
eprint: 1901.09054v2
file: 1901.09054v2.pdf
files:
- tmpn1ovn8br.pdf
month: Jan
note: 2020 IEEE Winter Conference on Applications of Computer Vision   (WACV), Snowmass
  Village, CO, USA, 2020
papis_id: b1c5c9db2305acf0ed45d12a61594377
primaryclass: cs.LG
ref: DeepLearningOBarz2019
time-added: 2023-05-15-09:33:29
title: Deep Learning on Small Datasets without Pre-Training using Cosine Loss
type: article
url: http://arxiv.org/abs/1901.09054v2
year: 2019
download: 'https://arxiv.org/pdf/1901.09054v2.pdf'
