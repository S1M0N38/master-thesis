abstract: 'Defense models against adversarial attacks have grown significantly, but
  the lack of practical evaluation methods has hindered progress. Evaluation can be
  defined as looking for defense models'' lower bound of robustness given a budget
  number of iterations and a test dataset. A practical evaluation method should be
  convenient (i.e., parameter-free), efficient (i.e., fewer iterations) and reliable
  (i.e., approaching the lower bound of robustness). Towards this target, we propose
  a parameter-free Adaptive Auto Attack (A$^3$) evaluation method which addresses
  the efficiency and reliability in a test-time-training fashion. Specifically, by
  observing that adversarial examples to a specific defense model follow some regularities
  in their starting points, we design an Adaptive Direction Initialization strategy
  to speed up the evaluation. Furthermore, to approach the lower bound of robustness
  under the budget number of iterations, we propose an online statistics-based discarding
  strategy that automatically identifies and abandons hard-to-attack images. Extensive
  experiments demonstrate the effectiveness of our A$^3$. Particularly, we apply A$^3$
  to nearly 50 widely-used defense models. By consuming much fewer iterations than
  existing methods, i.e., $1/10$ on average (10$\times$ speed up), we achieve lower
  robust accuracy in all cases. Notably, we won $\textbf{first place}$ out of 1681
  teams in CVPR 2021 White-box Adversarial Attacks on Defense Models competitions
  with this method. Code is available at: $\href{https://github.com/liuye6666/adaptive_auto_attack}{https://github.com/liuye6666/adaptive\_auto\_attack}$'
archiveprefix: arXiv
author: Liu, Ye and Cheng, Yaya and Gao, Lianli and Liu, Xianglong and Zhang, Qilong
  and Song, Jingkuan
author_list:
- family: Liu
  given: Ye
- family: Cheng
  given: Yaya
- family: Gao
  given: Lianli
- family: Liu
  given: Xianglong
- family: Zhang
  given: Qilong
- family: Song
  given: Jingkuan
eprint: 2203.05154v3
file: 2203.05154v3.pdf
files:
- tmp0a787d2t.pdf
month: Mar
primaryclass: cs.CV
ref: 2203.05154v3
tags: CVPR2022
time-added: 2023-03-07-14:33:32
title: Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack
type: article
url: http://arxiv.org/abs/2203.05154v3
year: '2022'
notes: 'Propose a parameter-free Adaptive Auto Attack (A3) evaluation method
  which addresses the efficiency and reliability in a test-time-training
  fashion. 1st place in CVPR 2021 White-box Adversarial Attacks on Defense
  Models.'
code: 'https://github.com/liuye6666/adaptive_auto_attack'
