abstract: 'Transferability of adversarial examples is of central importance for attacking
  an unknown model, which facilitates adversarial attacks in more practical scenarios,
  e.g., black-box attacks. Existing transferable attacks tend to craft adversarial
  examples by indiscriminately distorting features to degrade prediction accuracy
  in a source model without aware of intrinsic features of objects in the images.
  We argue that such brute-force degradation would introduce model-specific local
  optimum into adversarial examples, thus limiting the transferability. By contrast,
  we propose the Feature Importance-aware Attack (FIA), which disrupts important object-aware
  features that dominate model decisions consistently. More specifically, we obtain
  feature importance by introducing the aggregate gradient, which averages the gradients
  with respect to feature maps of the source model, computed on a batch of random
  transforms of the original clean image. The gradients will be highly correlated
  to objects of interest, and such correlation presents invariance across different
  models. Besides, the random transforms will preserve intrinsic features of objects
  and suppress model-specific information. Finally, the feature importance guides
  to search for adversarial examples towards disrupting critical features, achieving
  stronger transferability. Extensive experimental evaluation demonstrates the effectiveness
  and superior performance of the proposed FIA, i.e., improving the success rate by
  9.5% against normally trained models and 12.8% against defense models as compared
  to the state-of-the-art transferable attacks. Code is available at: https://github.com/hcguoO0/FIA'
archiveprefix: arXiv
author: Wang, Zhibo and Guo, Hengchang and Zhang, Zhifei and Liu, Wenxin and Qin,
  Zhan and Ren, Kui
author_list:
- family: Wang
  given: Zhibo
- family: Guo
  given: Hengchang
- family: Zhang
  given: Zhifei
- family: Liu
  given: Wenxin
- family: Qin
  given: Zhan
- family: Ren
  given: Kui
eprint: 2107.14185v3
file: 2107.14185v3.pdf
files:
- tmpn4hr7mag.pdf
month: Jul
primaryclass: cs.CV
ref: 2107.14185v3
tags: ICCV2021 attack
time-added: 2023-03-06-18:12:57
title: Feature Importance-aware Transferable Adversarial Attacks
type: article
url: http://arxiv.org/abs/2107.14185v3
year: '2021'
notes: 'Feature Importance-aware Attack (FIA) disrupts important object-aware
  features that dominate model decisions consistently. This make adversarial
  attack model agnostic.'
code: 'https://github.com/hcguoO0/FIA'
