abstract: This paper investigates strategies that defend against adversarial-example
  attacks on image-classification systems by transforming the inputs before feeding
  them to the system. Specifically, we study applying image transformations such as
  bit-depth reduction, JPEG compression, total variance minimization, and image quilting
  before feeding the image to a convolutional network classifier. Our experiments
  on ImageNet show that total variance minimization and image quilting are very effective
  defenses in practice, in particular, when the network is trained on transformed
  images. The strength of those defenses lies in their non-differentiable nature and
  their inherent randomness, which makes it difficult for an adversary to circumvent
  the defenses. Our best defense eliminates 60% of strong gray-box and 90% of strong
  black-box attacks by a variety of major attack methods
archiveprefix: arXiv
author: Guo, Chuan and Rana, Mayank and Cisse, Moustapha and van der Maaten, Laurens
author_list:
- family: Guo
  given: Chuan
- family: Rana
  given: Mayank
- family: Cisse
  given: Moustapha
- family: van der Maaten
  given: Laurens
eprint: 1711.00117v3
file: 1711.00117v3.pdf
files:
- tmp25w5o-rn.pdf
month: Oct
papis_id: f4eaeab81d42c049098f9eb60dd8eb63
primaryclass: cs.CV
ref: CounteringAdveGuoC2017
time-added: 2023-11-21-16:57:38
title: Countering Adversarial Images using Input Transformations
type: article
url: http://arxiv.org/abs/1711.00117v3
year: '2017'
