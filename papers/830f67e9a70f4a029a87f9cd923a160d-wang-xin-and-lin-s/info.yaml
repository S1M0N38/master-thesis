abstract: This paper aims to explain adversarial attacks in terms of how adversarial
  perturbations contribute to the attacking task. We estimate attributions of different
  image regions to the decrease of the attacking cost based on the Shapley value.
  We define and quantify interactions among adversarial perturbation pixels, and decompose
  the entire perturbation map into relatively independent perturbation components.
  The decomposition of the perturbation map shows that adversarially-trained DNNs
  have more perturbation components in the foreground than normally-trained DNNs.
  Moreover, compared to the normally-trained DNN, the adversarially-trained DNN have
  more components which mainly decrease the score of the true category. Above analyses
  provide new insights into the understanding of adversarial attacks.
archiveprefix: arXiv
author: Wang, Xin and Lin, Shuyun and Zhang, Hao and Zhu, Yufei and Zhang, Quanshi
author_list:
- family: Wang
  given: Xin
- family: Lin
  given: Shuyun
- family: Zhang
  given: Hao
- family: Zhu
  given: Yufei
- family: Zhang
  given: Quanshi
eprint: 2108.06895v1
file: 2108.06895v1.pdf
files:
- tmp5d7u90wd.pdf
month: Aug
primaryclass: cs.LG
ref: 2108.06895v1
tags: ICCV2021
time-added: 2023-03-07-09:19:34
title: Interpreting Attributions and Interactions of Adversarial Attacks
type: article
url: http://arxiv.org/abs/2108.06895v1
year: '2021'
notes: 'Explain adversarial attacks in terms of how adversarial perturbations
  contribute to the attacking task. Attributions of different image regions to
  the decrease of the attacking cost. Quantify interactions among adversarial
  perturbation pixels.'
